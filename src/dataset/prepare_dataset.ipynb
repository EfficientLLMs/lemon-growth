{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the Alpaca-GPT4 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "from transformers import AutoTokenizer, default_data_collator\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# seed\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(1006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "class args:\n",
    "    data = '../../data/alpaca_gpt4_data.json'\n",
    "    ratio = 0.8\n",
    "    max_seq_length = 512\n",
    "    batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_no_input(row):\n",
    "    return (\"Below is an instruction that describes a task. \"\n",
    "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "            \"### Instruction:\\n{instruction}\\n\\n### Response:\\n\").format_map(row)\n",
    "\n",
    "def prompt_with_input(row):\n",
    "    return (\"Below is an instruction that describes a task. \"\n",
    "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "            \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\").format_map(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(row):\n",
    "    return prompt_no_input(row) if row[\"input\"] == \"\" else prompt_with_input(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack(dataset, max_seq_len, tokenizer):\n",
    "    tkds_ids = tokenizer([s[\"example\"] for s in dataset])[\"input_ids\"]\n",
    "    \n",
    "    all_token_ids = []\n",
    "    for tokenized_input in tkds_ids:\n",
    "        all_token_ids.extend(tokenized_input + [tokenizer.eos_token_id])\n",
    "    \n",
    "    packed_ds = []\n",
    "    for i in range(0, len(all_token_ids), max_seq_len+1):\n",
    "        input_ids = all_token_ids[i : i + max_seq_len+1]\n",
    "        if len(input_ids) == (max_seq_len+1):\n",
    "            packed_ds.append({\"input_ids\": input_ids, \"labels\": input_ids})\n",
    "    return packed_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(args, tokenizer):\n",
    "    with open(args.data, \"r\") as f:\n",
    "        alpaca = json.load(f)\n",
    "    prompts = [create_prompt(row) for row in alpaca]\n",
    "    outputs = [row['output'] + tokenizer.eos_token for row in alpaca]\n",
    "    dataset = [{\"prompt\":s, \"output\":t, \"example\": s+t} for s, t in zip(prompts, outputs)]\n",
    "    random.shuffle(dataset)\n",
    "    train_size = int(args.ratio * len(dataset))\n",
    "    train_dataset = dataset[:train_size]\n",
    "    eval_dataset = dataset[train_size:]\n",
    "    train_ds_packed = pack(train_dataset, args.max_seq_length, tokenizer)\n",
    "    eval_ds_packed = pack(eval_dataset, args.max_seq_length, tokenizer)\n",
    "    return train_ds_packed, eval_ds_packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"EleutherAI/pythia-160m\",  # standard model; the same tokenizer is used for all models\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset and dataloader\n",
    "train_ds_packed, eval_ds_packed = get_dataset(args, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_ds_packed,\n",
    "    batch_size=args.batch_size,\n",
    "    collate_fn=default_data_collator,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_ds_packed,\n",
    "    batch_size=args.batch_size,\n",
    "    collate_fn=default_data_collator,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for future use\n",
    "torch.save(train_dataloader, \"../../data/train_dataloader.pt\")\n",
    "torch.save(eval_dataloader, \"../../data/eval_dataloader.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[30003,   310,   271,  ...,  3527,    14,  4924],\n",
      "        [   13,   277,  2246,  ...,   281,  5834,   697],\n",
      "        [ 1211,   277, 19934,  ..., 50275,    93,   370],\n",
      "        [ 2222,    13,   933,  ...,  3909,  2425,   187]]), 'labels': tensor([[30003,   310,   271,  ...,  3527,    14,  4924],\n",
      "        [   13,   277,  2246,  ...,   281,  5834,   697],\n",
      "        [ 1211,   277, 19934,  ..., 50275,    93,   370],\n",
      "        [ 2222,    13,   933,  ...,  3909,  2425,   187]])}\n"
     ]
    }
   ],
   "source": [
    "# check for dataloader\n",
    "eval_dataloader = torch.load(\"../../data/eval_dataloader.pt\")\n",
    "for batch in eval_dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "styletunedlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
